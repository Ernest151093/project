# Задача<br>
Построить модель, которая будет искать токсичные комментарии и отправлять их на модерацию.

# Ход работы<br>
1. Был проведен анализ, полученных датасетов. 
2. Проведена предобработка данных: лемматизация, удаление лишних слов (союзы, предлоги и т.д), посчитана величина TF-IDF. Устранен дисбаланс классов.
3. Проведено обучение модели с помощью следующих моделей: LogisticRegression, RandomForestClassifier. Также на данном этапе был проведен анализ по устранению дисбаланса.

# Результат<br>
В данной задаче лучше всего справилась модель LogisticRegression (f1-метрика > 0.75)

# Используемые библиотеки<br>
*pandas, sklearn, nltk, pymystem3, re, CatBoost*
