# Данные<br>
В моем распоряжении были следующие данные:<br>
1. Текст;<br>
2. Токсичность (булев тип).<br>

# Задача<br>
Построить модель, которая будет искать токсичные комментарии и отправлять их на модерацию.

# Ход работы<br>
1. Был проведен анализ, полученных датасетов. 
2. Проведена предобработка данных: лемматизация, удаление лишних слов (союзы, предлоги и т.д), посчитана вличина TF-IDF.
3. Проведено обучение модели с помощью следующих моделей: LogisticRegression, RandomForestClassifier. Также на данном этапе был проведен анализ по устранению дисбаланса.

# Используемые библиотеки<br>
*pandas, sklearn, nltk, pymystem3, re, CatBoost*
